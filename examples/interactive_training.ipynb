{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from config.experiment_config import create_experiment_config\n",
    "from experiments.traditional import TraditionalExperiment\n",
    "from models.data import get_dataset\n",
    "from models.factory import get_model\n",
    "from utils.logging import setup_logging, get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "setup_logging()\n",
    "\n",
    "# Enable CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configuration\n",
    "CHECKPOINT_PATH = \"checkpoints/wideresnet/wideresnet_best.pt\"\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "# Create checkpoint directory\n",
    "Path(CHECKPOINT_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Training transforms\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5071, 0.4867, 0.4408],\n",
    "        std=[0.2675, 0.2565, 0.2761]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Test transforms\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5071, 0.4867, 0.4408],\n",
    "        std=[0.2675, 0.2565, 0.2761]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Training Visualizer\n",
    "class TrainingVisualizer:\n",
    "    def __init__(self, epochs):\n",
    "        self.epochs = epochs\n",
    "        self.train_losses = []\n",
    "        self.train_accs = []\n",
    "        self.val_accs = []\n",
    "        self.lrs = []\n",
    "        \n",
    "        # Create the figure and axes\n",
    "        plt.ion()\n",
    "        self.fig, (self.ax1, self.ax2, self.ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        self.setup_plots()\n",
    "        \n",
    "    def setup_plots(self):\n",
    "        # Loss plot\n",
    "        self.ax1.set_title('Training Loss')\n",
    "        self.ax1.set_xlabel('Epoch')\n",
    "        self.ax1.set_ylabel('Loss')\n",
    "        self.ax1.grid(True)\n",
    "        \n",
    "        # Accuracy plot\n",
    "        self.ax2.set_title('Accuracy')\n",
    "        self.ax2.set_xlabel('Epoch')\n",
    "        self.ax2.set_ylabel('Accuracy (%)')\n",
    "        self.ax2.grid(True)\n",
    "        \n",
    "        # Learning rate plot\n",
    "        self.ax3.set_title('Learning Rate')\n",
    "        self.ax3.set_xlabel('Epoch')\n",
    "        self.ax3.set_ylabel('Learning Rate')\n",
    "        self.ax3.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "    \n",
    "    def update(self, epoch, train_loss, train_acc, val_acc, lr):\n",
    "        self.train_losses.append(train_loss)\n",
    "        self.train_accs.append(train_acc)\n",
    "        self.val_accs.append(val_acc)\n",
    "        self.lrs.append(lr)\n",
    "        \n",
    "        epochs = list(range(1, len(self.train_losses) + 1))\n",
    "        \n",
    "        # Update loss plot\n",
    "        self.ax1.clear()\n",
    "        self.ax1.plot(epochs, self.train_losses)\n",
    "        self.ax1.set_title('Training Loss')\n",
    "        self.ax1.set_xlabel('Epoch')\n",
    "        self.ax1.set_ylabel('Loss')\n",
    "        self.ax1.grid(True)\n",
    "        \n",
    "        # Update accuracy plot\n",
    "        self.ax2.clear()\n",
    "        self.ax2.plot(epochs, self.train_accs, label='Train')\n",
    "        self.ax2.plot(epochs, self.val_accs, label='Validation')\n",
    "        self.ax2.set_title('Accuracy')\n",
    "        self.ax2.set_xlabel('Epoch')\n",
    "        self.ax2.set_ylabel('Accuracy (%)')\n",
    "        self.ax2.legend()\n",
    "        self.ax2.grid(True)\n",
    "        \n",
    "        # Update learning rate plot\n",
    "        self.ax3.clear()\n",
    "        self.ax3.plot(epochs, self.lrs)\n",
    "        self.ax3.set_title('Learning Rate')\n",
    "        self.ax3.set_xlabel('Epoch')\n",
    "        self.ax3.set_ylabel('Learning Rate')\n",
    "        self.ax3.set_yscale('log')\n",
    "        self.ax3.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.draw()\n",
    "        plt.pause(0.1)\n",
    "    \n",
    "    def save(self, path):\n",
    "        plt.savefig(path)\n",
    "        \n",
    "    def close(self):\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Training Function\n",
    "def train_model_interactive(model, train_loader, val_loader, epochs=200, resume=True):\n",
    "    \"\"\"Train model with real-time visualization.\"\"\"\n",
    "    logger.info(\"Starting interactive training...\")\n",
    "    \n",
    "    # Enable cuDNN benchmarking\n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=0.1,\n",
    "        momentum=0.9,\n",
    "        weight_decay=5e-4,\n",
    "        nesterov=True\n",
    "    )\n",
    "    \n",
    "    milestones = [60, 120, 160]\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer,\n",
    "        milestones=milestones,\n",
    "        gamma=0.2\n",
    "    )\n",
    "    \n",
    "    # Try to load checkpoint\n",
    "    start_epoch = 0\n",
    "    best_acc = 0.0\n",
    "    if resume and Path(CHECKPOINT_PATH).exists():\n",
    "        logger.info(f\"Resuming from checkpoint: {CHECKPOINT_PATH}\")\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH, map_location=device, weights_only=True)\n",
    "        if isinstance(checkpoint, dict) and 'epoch' in checkpoint:\n",
    "            start_epoch = checkpoint['epoch'] + 1\n",
    "            best_acc = checkpoint.get('acc', 0.0)\n",
    "            if 'model_state_dict' in checkpoint:\n",
    "                model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            elif 'state_dict' in checkpoint:\n",
    "                model.load_state_dict(checkpoint['state_dict'])\n",
    "            else:\n",
    "                model.load_state_dict(checkpoint)\n",
    "            if 'optimizer_state_dict' in checkpoint:\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            if 'scheduler_state_dict' in checkpoint:\n",
    "                scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "            logger.info(f\"Resuming from epoch {start_epoch} with best accuracy: {best_acc:.2f}%\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    \n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    visualizer = TrainingVisualizer(epochs)\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(start_epoch, epochs):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')\n",
    "            for inputs, targets in pbar:\n",
    "                inputs = inputs.to(device, non_blocking=True)\n",
    "                targets = targets.to(device, non_blocking=True)\n",
    "                \n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                \n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "                \n",
    "                current_lr = optimizer.param_groups[0]['lr']\n",
    "                pbar.set_postfix({\n",
    "                    'loss': f'{train_loss/total:.3f}',\n",
    "                    'acc': f'{100.*correct/total:.2f}%',\n",
    "                    'lr': f'{current_lr:.3e}'\n",
    "                })\n",
    "            \n",
    "            train_acc = 100.*correct/total\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "                for inputs, targets in val_loader:\n",
    "                    inputs = inputs.to(device, non_blocking=True)\n",
    "                    targets = targets.to(device, non_blocking=True)\n",
    "                    outputs = model(inputs)\n",
    "                    \n",
    "                    _, predicted = outputs.max(1)\n",
    "                    total += targets.size(0)\n",
    "                    correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            val_acc = 100.*correct/total\n",
    "            logger.info(f'Epoch {epoch+1}: Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}% (lr={current_lr:.3e})')\n",
    "            \n",
    "            # Update visualization\n",
    "            visualizer.update(epoch+1, train_loss/len(train_loader), train_acc, val_acc, current_lr)\n",
    "            \n",
    "            # Save checkpoint if best accuracy\n",
    "            if val_acc > best_acc:\n",
    "                logger.info(f'Saving checkpoint... ({val_acc:.2f}%)')\n",
    "                best_acc = val_acc\n",
    "                state = {\n",
    "                    'model_state_dict': model.module.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict(),\n",
    "                    'acc': val_acc,\n",
    "                    'epoch': epoch,\n",
    "                }\n",
    "                torch.save(state, CHECKPOINT_PATH)\n",
    "            \n",
    "            scheduler.step()\n",
    "        \n",
    "        # Save final plot\n",
    "        visualizer.save('training_curves.png')\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        logger.info('Training interrupted by user')\n",
    "    finally:\n",
    "        visualizer.close()\n",
    "    \n",
    "    logger.info(f'Training completed. Best accuracy: {best_acc:.2f}%')\n",
    "    return best_acc > 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Setup Function\n",
    "def setup_training(resume=True, subset_size=None):\n",
    "    \"\"\"Set up datasets and model for training.\"\"\"\n",
    "    # Get datasets\n",
    "    train_dataset = get_dataset(\"cifar100\", train=True, transform=transform_train)\n",
    "    val_dataset = get_dataset(\"cifar100\", train=False, transform=transform_test)\n",
    "    \n",
    "    # Apply subset if specified\n",
    "    if subset_size:\n",
    "        train_dataset = torch.utils.data.Subset(\n",
    "            train_dataset, \n",
    "            range(min(subset_size, len(train_dataset)))\n",
    "        )\n",
    "        val_dataset = torch.utils.data.Subset(\n",
    "            val_dataset,\n",
    "            range(min(subset_size // 5, len(val_dataset)))\n",
    "        )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "        persistent_workers=True,\n",
    "        prefetch_factor=3\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE*2,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "        prefetch_factor=3\n",
    "    )\n",
    "    \n",
    "    # Create model\n",
    "    model = get_model(\"cifar100\", \"wrn-28-10\")\n",
    "    \n",
    "    return model, train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Run Training\n",
    "# Choose your scenario:\n",
    "\n",
    "# Scenario 1: Resume training from checkpoint\n",
    "model, train_loader, val_loader = setup_training(resume=True)\n",
    "train_model_interactive(model, train_loader, val_loader, resume=True)\n",
    "\n",
    "# Scenario 2: Train from scratch\n",
    "# model, train_loader, val_loader = setup_training(resume=False)\n",
    "# train_model_interactive(model, train_loader, val_loader, resume=False)\n",
    "\n",
    "# Scenario 3: Train with subset\n",
    "# model, train_loader, val_loader = setup_training(resume=True, subset_size=10000)\n",
    "# train_model_interactive(model, train_loader, val_loader, resume=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
